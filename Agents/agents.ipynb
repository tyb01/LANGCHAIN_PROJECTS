{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a1b5b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools import WikipediaQueryRun\n",
    "from langchain_community.utilities import WikipediaAPIWrapper\n",
    "\n",
    "apiwrapper = WikipediaAPIWrapper(top_k_results=1,doc_content_chars_max=200)\n",
    "\n",
    "wiki_tool = WikipediaQueryRun(api_wrapper=apiwrapper)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "34f903df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "import faiss\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.docstore.in_memory import InMemoryDocstore\n",
    "from uuid import uuid4\n",
    "\n",
    "loader = WebBaseLoader(\"https://python.langchain.com/docs/integrations/tools/\")\n",
    "\n",
    "docs = loader.load()\n",
    "\n",
    "chunks = RecursiveCharacterTextSplitter(chunk_size = 1000, chunk_overlap = 200).split_documents(docs)\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(model_name = \"sentence-transformers/all-mpnet-base-v2\")\n",
    "\n",
    "vectordb = FAISS.from_documents(\n",
    "    documents=chunks,\n",
    "    embedding=embeddings\n",
    ")\n",
    "\n",
    "retriever = vectordb.as_retriever()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "531fe070",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "langsmith_search\n"
     ]
    }
   ],
   "source": [
    "from langchain.tools.retriever import create_retriever_tool\n",
    "\n",
    "ret_tool = create_retriever_tool(retriever,\"langsmith_search\",\n",
    "                      \"Search any information about langsmit, for any question about langsmith tool, you should use this tool\")\n",
    "\n",
    "print(ret_tool.name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e34b8e75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arxiv\n"
     ]
    }
   ],
   "source": [
    "#ARXIV TOOL\n",
    "from langchain_community.utilities import ArxivAPIWrapper\n",
    "from langchain_community.tools.arxiv.tool import ArxivQueryRun\n",
    "\n",
    "arxivwrapper = ArxivAPIWrapper(top_k_results=1,doc_content_chars_max=200)\n",
    "arxiv_tool = ArxivQueryRun(api_wrapper=arxivwrapper)\n",
    "\n",
    "print(arxiv_tool.name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "532a8e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [wiki_tool,arxiv_tool,ret_tool]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a9c4d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Agents\n",
    "from langchain.agents import create"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
